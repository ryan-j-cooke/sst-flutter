import 'dart:async';
import 'dart:io';
import 'dart:isolate';
import 'dart:typed_data';

import 'package:archive/archive.dart';
import 'package:flutter/material.dart';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';
import 'package:sherpa_onnx/sherpa_onnx.dart';

void main() {
  // Initialize sherpa-onnx bindings before using any sherpa-onnx functionality
  initBindings();
  runApp(const MyApp());
}

// Sherpa-ONNX model types - these are multilingual and support many languages
// Model names match the actual filenames from: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models
enum SherpaModelType {
  zipformerEn('Zipformer EN', 'sherpa-onnx-zipformer-en-2023-06-26', '~293 MB'),
  zipformerTh(
    'Zipformer TH',
    'sherpa-onnx-zipformer-thai-2024-06-20',
    '~663 MB',
  ),
  zipformerZh(
    'Zipformer ZH',
    'sherpa-onnx-zipformer-zh-en-2023-11-22',
    '~298 MB',
  ),
  zipformerRu('Zipformer RU', 'sherpa-onnx-zipformer-ru-2024-09-18', '~284 MB'),
  zipformerKo(
    'Zipformer KO',
    'sherpa-onnx-zipformer-korean-2024-06-24',
    '~314 MB',
  ),
  paraformerZh(
    'Paraformer ZH',
    'sherpa-onnx-paraformer-zh-2024-03-09',
    '~950 MB',
  ),
  whisperTiny('Whisper Tiny', 'sherpa-onnx-whisper-tiny', '~111 MB'),
  whisperBase('Whisper Base', 'sherpa-onnx-whisper-base', '~198 MB'),
  whisperSmall('Whisper Small', 'sherpa-onnx-whisper-small', '~610 MB');

  final String displayName;
  final String modelName;
  final String fileSize;

  const SherpaModelType(this.displayName, this.modelName, this.fileSize);
}

// Language codes for Sherpa-ONNX
const languages = [
  Language('English', 'en'),
  Language('Hebrew', 'he'),
  Language('Français', 'fr'),
  Language('ไทย', 'th'),
  Language('中文', 'zh'),
  Language('Pусский', 'ru'),
  Language('Italiano', 'it'),
  Language('Español', 'es'),
  Language('Deutsch', 'de'),
  Language('日本語', 'ja'),
  Language('한국어', 'ko'),
];

class Language {
  final String name;
  final String code;

  const Language(this.name, this.code);
}

// Isolate function for background extraction
Future<void> _extractModelInIsolate(Map<String, dynamic> params) async {
  final sendPort = params['sendPort'] as SendPort;
  try {
    final tarBz2Path = params['tarBz2Path'] as String;
    final modelDir = params['modelDir'] as String;
    final modelName = params['modelName'] as String;

    sendPort.send({'status': 'reading', 'progress': 0.0});

    // Read the tar.bz2 file
    final tarBz2File = File(tarBz2Path);
    final tarBz2Bytes = await tarBz2File.readAsBytes();
    sendPort.send({
      'status': 'read',
      'progress': 10.0,
      'size': tarBz2Bytes.length,
    });

    // Decompress bzip2
    sendPort.send({'status': 'decompressing', 'progress': 15.0});
    final bz2Decoder = BZip2Decoder();
    final tarBytes = bz2Decoder.decodeBytes(tarBz2Bytes);
    sendPort.send({
      'status': 'decompressed',
      'progress': 40.0,
      'size': tarBytes.length,
    });

    // Extract tar archive
    sendPort.send({'status': 'decoding', 'progress': 45.0});
    final tarDecoder = TarDecoder();
    final archive = tarDecoder.decodeBytes(tarBytes);
    sendPort.send({
      'status': 'decoded',
      'progress': 50.0,
      'fileCount': archive.files.length,
    });

    // Extract all files
    int fileCount = 0;
    int totalFiles = archive.files.where((f) => f.isFile).length;

    for (final file in archive.files) {
      if (file.isFile) {
        fileCount++;
        final filename = file.name;

        // Calculate progress (50-100%)
        final progress = 50.0 + (fileCount / totalFiles) * 50.0;
        sendPort.send({
          'status': 'extracting',
          'progress': progress,
          'fileCount': fileCount,
          'totalFiles': totalFiles,
          'currentFile': filename,
        });

        // Handle nested paths in the archive
        final pathParts = filename.split('/');
        // Find the model name directory and skip it
        String relativePath = filename;
        for (int i = 0; i < pathParts.length; i++) {
          if (pathParts[i] == modelName || pathParts[i].startsWith(modelName)) {
            if (i + 1 < pathParts.length) {
              relativePath = pathParts.sublist(i + 1).join('/');
            } else {
              // If the model name is the last part, use just the filename
              relativePath = pathParts.last;
            }
            break;
          }
        }

        // If no model name found, try to use the path after the first directory
        if (relativePath == filename && pathParts.length > 1) {
          relativePath = pathParts.sublist(1).join('/');
        }

        final outputFile = File('$modelDir/$relativePath');
        try {
          await outputFile.parent.create(recursive: true);
          await outputFile.writeAsBytes(file.content as List<int>);
        } catch (e) {
          sendPort.send({'error': 'Failed to extract $filename: $e'});
        }
      }
    }

    sendPort.send({
      'status': 'completed',
      'progress': 100.0,
      'fileCount': fileCount,
    });
  } catch (e, stackTrace) {
    sendPort.send({
      'error': 'Extraction failed: $e',
      'stackTrace': stackTrace.toString(),
    });
  }
}

class MyApp extends StatelessWidget {
  const MyApp({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Sherpa-ONNX STT - Multilingual',
      theme: ThemeData(primarySwatch: Colors.blue),
      home: const SpeechTestPage(),
    );
  }
}

class SpeechTestPage extends StatefulWidget {
  const SpeechTestPage({super.key});

  @override
  State<SpeechTestPage> createState() => _SpeechTestPageState();
}

class _SpeechTestPageState extends State<SpeechTestPage> {
  final AudioRecorder _audioRecorder = AudioRecorder();
  OfflineRecognizer? _recognizer;
  String? _modelDir;

  bool _isInitializing = false;
  bool _isDownloading = false;
  bool _isRecording = false;
  bool _isTranscribing = false;
  String _transcription = 'Press the button to start recording';
  String _statusMessage = 'Initializing...';
  String? _currentRecordingPath;
  Duration _recordingDuration = Duration.zero;
  Duration _transcriptionElapsedTime = Duration.zero;
  Timer? _recordingTimer;
  Timer? _transcriptionTimer;
  bool _showOutput = false;
  StreamSubscription<String>? _streamSubscription;
  double _extractionProgress = 0.0;
  String _extractionStatus = '';

  Language selectedLang = languages.firstWhere(
    (l) => l.code == 'th',
    orElse: () => languages.first,
  );
  SherpaModelType selectedModel = SherpaModelType.zipformerTh;

  @override
  void initState() {
    super.initState();
    _initializeInBackground();
  }

  Future<void> _initializeInBackground() async {
    setState(() {
      _isInitializing = true;
      _statusMessage = 'Initializing app...';
    });

    // Initialize in background to keep UI responsive
    await _initializeSherpa();
  }

  Future<void> _initializeSherpa() async {
    if (!_isInitializing) {
      setState(() {
        _isInitializing = true;
        _statusMessage = 'Initializing Sherpa-ONNX...';
      });
    }

    try {
      // Get model directory
      final documentsDir = await getApplicationDocumentsDirectory();
      _modelDir =
          '${documentsDir.path}/sherpa_onnx_models/${selectedModel.modelName}';
      await Directory(_modelDir!).create(recursive: true);

      // Step 1: Check if model files already exist
      final encoderFile = File('$_modelDir/encoder.onnx');
      final decoderFile = File('$_modelDir/decoder.onnx');
      final joinerFile = File('$_modelDir/joiner.onnx');
      final tokensFile = File('$_modelDir/tokens.txt');

      final modelExists =
          await encoderFile.exists() &&
          await decoderFile.exists() &&
          await joinerFile.exists() &&
          await tokensFile.exists();

      if (modelExists) {
        print('Model files already exist, initializing...');
        setState(() {
          _statusMessage = 'Model found, initializing...';
        });
      } else {
        // Step 2: Model doesn't exist, check if downloaded file exists
        final tempDir = await getTemporaryDirectory();
        final downloadedFile = File(
          '${tempDir.path}/${selectedModel.modelName}.tar.bz2',
        );

        if (await downloadedFile.exists()) {
          // Check file size against remote
          setState(() {
            _statusMessage = 'Checking downloaded file...';
          });

          try {
            final localSize = await downloadedFile.length();
            final remoteSize = await _getRemoteFileSize(
              'https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/${selectedModel.modelName}.tar.bz2',
            );

            if (remoteSize != null && localSize == remoteSize) {
              // File exists and size matches, extract it
              print(
                'Downloaded file exists and size matches ($localSize bytes), extracting...',
              );
              setState(() {
                _isDownloading = true;
                _statusMessage = 'Extracting existing download...';
              });
              await _extractModel(downloadedFile);
            } else {
              // Size doesn't match or couldn't get remote size, re-download
              print(
                'Downloaded file size mismatch (local: $localSize, remote: $remoteSize), re-downloading...',
              );
              await downloadedFile.delete();
              setState(() {
                _isDownloading = true;
                _statusMessage =
                    'Downloading ${selectedModel.displayName} model...\nThis may take a while...';
              });
              await _downloadModel();
            }
          } catch (e) {
            print('Error checking file size: $e, re-downloading...');
            // If we can't check, re-download to be safe
            if (await downloadedFile.exists()) {
              await downloadedFile.delete();
            }
            setState(() {
              _isDownloading = true;
              _statusMessage =
                  'Downloading ${selectedModel.displayName} model...\nThis may take a while...';
            });
            await _downloadModel();
          }
        } else {
          // Step 3: No downloaded file, download it
          print('No model or downloaded file found, downloading...');
          setState(() {
            _isDownloading = true;
            _statusMessage =
                'Downloading ${selectedModel.displayName} model...\nThis may take a while...';
          });
          await _downloadModel();
        }
      }

      // Initialize Sherpa-ONNX recognizer with all required files
      final encoderPath = '$_modelDir/encoder.onnx';
      final decoderPath = '$_modelDir/decoder.onnx';
      final joinerPath = '$_modelDir/joiner.onnx';
      final tokensPath = '$_modelDir/tokens.txt';

      // Verify all files exist before initialization
      if (!await File(encoderPath).exists() ||
          !await File(decoderPath).exists() ||
          !await File(joinerPath).exists() ||
          !await File(tokensPath).exists()) {
        throw Exception(
          'Model files missing. Expected:\n- $encoderPath\n- $decoderPath\n- $joinerPath\n- $tokensPath',
        );
      }

      print(
        'Initializing recognizer with:\n- encoder: $encoderPath\n- decoder: $decoderPath\n- joiner: $joinerPath\n- tokens: $tokensPath',
      );

      // Initialize with transducer model config (for Zipformer models)
      // Zipformer models use the transducer architecture
      final transducerConfig = OfflineTransducerModelConfig(
        encoder: encoderPath,
        decoder: decoderPath,
        joiner: joinerPath,
      );
      final modelConfig = OfflineModelConfig(
        transducer: transducerConfig,
        tokens: tokensPath,
      );
      final recognizerConfig = OfflineRecognizerConfig(
        model: modelConfig,
        feat: FeatureConfig(sampleRate: 16000),
      );
      _recognizer = OfflineRecognizer(recognizerConfig);

      setState(() {
        _isInitializing = false;
        _isDownloading = false;
        _statusMessage = 'Ready (Sherpa-ONNX ${selectedModel.displayName})';
      });
    } catch (e, stackTrace) {
      setState(() {
        _isInitializing = false;
        _isDownloading = false;
        _statusMessage = 'Error initializing: $e';
      });
      print('Error initializing Sherpa-ONNX: $e');
      print('Stack trace: $stackTrace');
    }
  }

  /// Get the size of a remote file via HEAD request
  Future<int?> _getRemoteFileSize(String url) async {
    try {
      final client = HttpClient();
      final request = await client.headUrl(Uri.parse(url));
      final response = await request.close();
      client.close();

      if (response.statusCode == 200) {
        final contentLength = response.contentLength;
        return contentLength > 0 ? contentLength : null;
      }
      return null;
    } catch (e) {
      print('Error getting remote file size: $e');
      return null;
    }
  }

  Future<void> _downloadModel() async {
    try {
      // Sherpa-ONNX models are typically distributed as tar.bz2 files
      // Construct the download URL for the model
      // Format: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/{model-name}.tar.bz2
      final modelUrl =
          'https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/${selectedModel.modelName}.tar.bz2';

      print('Downloading model from: $modelUrl'); // Debug: show the actual URL
      final client = HttpClient();
      final request = await client.getUrl(Uri.parse(modelUrl));
      final response = await request.close();

      if (response.statusCode != 200) {
        throw Exception('Failed to download model: ${response.statusCode}');
      }

      // Download to temporary file first
      final tempDir = await getTemporaryDirectory();
      final tempFile = File(
        '${tempDir.path}/${selectedModel.modelName}.tar.bz2',
      );
      final sink = tempFile.openWrite();

      int downloaded = 0;
      await for (final data in response) {
        sink.add(data);
        downloaded += data.length;
        if (mounted) {
          setState(() {
            _statusMessage =
                'Downloading ${selectedModel.displayName} model...\n${(downloaded / 1024 / 1024).toStringAsFixed(1)} MB';
          });
        }
      }
      await sink.close();
      client.close();

      // Extract the downloaded file
      await _extractModel(tempFile);
    } catch (e, stackTrace) {
      print('Error downloading model: $e');
      print('Stack trace: $stackTrace');
      throw Exception('Error downloading model: $e');
    }
  }

  Future<void> _extractModel(File tarBz2File) async {
    try {
      // First, check if model files already exist
      final encoderFile = File('$_modelDir/encoder.onnx');
      final decoderFile = File('$_modelDir/decoder.onnx');
      final joinerFile = File('$_modelDir/joiner.onnx');
      final tokensFile = File('$_modelDir/tokens.txt');

      // Check if all required files exist with expected names
      final allFilesExist =
          await encoderFile.exists() &&
          await decoderFile.exists() &&
          await joinerFile.exists() &&
          await tokensFile.exists();

      if (allFilesExist) {
        print('Model files already exist, skipping extraction');
        if (mounted) {
          setState(() {
            _extractionProgress = 100.0;
            _extractionStatus = 'Model files already extracted';
            _statusMessage = 'Model files found, verifying...';
          });
        }
        // Still verify and copy files if needed (in case they're in subdirectories)
        await _verifyAndCopyModelFiles();
        return;
      }

      // Check if files exist with different names (version-specific names)
      print(
        'Model files not found with expected names, checking for version-specific names...',
      );
      final foundFiles = await _findModelFiles();

      if (foundFiles['encoder'] != null &&
          foundFiles['decoder'] != null &&
          foundFiles['joiner'] != null &&
          foundFiles['tokens'] != null) {
        print(
          'Found model files with version-specific names, copying to expected names...',
        );
        if (mounted) {
          setState(() {
            _extractionProgress = 90.0;
            _extractionStatus = 'Copying files to expected names...';
            _statusMessage = 'Model files found, renaming...';
          });
        }
        // Copy files to expected names
        if (foundFiles['encoder'] != null && !await encoderFile.exists()) {
          await foundFiles['encoder']!.copy(encoderFile.path);
          print('Copied encoder to: ${encoderFile.path}');
        }
        if (foundFiles['decoder'] != null && !await decoderFile.exists()) {
          await foundFiles['decoder']!.copy(decoderFile.path);
          print('Copied decoder to: ${decoderFile.path}');
        }
        if (foundFiles['joiner'] != null && !await joinerFile.exists()) {
          await foundFiles['joiner']!.copy(joinerFile.path);
          print('Copied joiner to: ${joinerFile.path}');
        }
        if (foundFiles['tokens'] != null && !await tokensFile.exists()) {
          await foundFiles['tokens']!.copy(tokensFile.path);
          print('Copied tokens to: ${tokensFile.path}');
        }
        if (mounted) {
          setState(() {
            _extractionProgress = 100.0;
            _statusMessage = 'Model files ready';
          });
        }
        return;
      }

      // Files don't exist, proceed with extraction
      print('Model files not found, starting extraction...');

      // Create a receive port to get progress updates from the isolate
      final receivePort = ReceivePort();

      if (mounted) {
        setState(() {
          _extractionProgress = 0.0;
          _extractionStatus = 'Starting extraction...';
          _statusMessage = 'Extracting model... (0%)';
        });
      }

      // Spawn isolate for background extraction
      await Isolate.spawn(_extractModelInIsolate, {
        'sendPort': receivePort.sendPort,
        'tarBz2Path': tarBz2File.path,
        'modelDir': _modelDir!,
        'modelName': selectedModel.modelName,
      });

      // Listen for progress updates
      await for (final message in receivePort) {
        if (!mounted) break;

        if (message is Map<String, dynamic>) {
          if (message.containsKey('error')) {
            print('Extraction error: ${message['error']}');
            if (message.containsKey('stackTrace')) {
              print('Stack trace: ${message['stackTrace']}');
            }
            throw Exception(message['error']);
          }

          final status = message['status'] as String?;
          final progress = (message['progress'] as num?)?.toDouble() ?? 0.0;
          final fileCount = message['fileCount'] as int?;
          final totalFiles = message['totalFiles'] as int?;
          final currentFile = message['currentFile'] as String?;

          _extractionProgress = progress;

          String statusText = '';
          switch (status) {
            case 'reading':
              statusText = 'Reading archive...';
              break;
            case 'read':
              final size = message['size'] as int?;
              if (size != null) {
                statusText =
                    'Read ${(size / 1024 / 1024).toStringAsFixed(1)} MB';
              }
              break;
            case 'decompressing':
              statusText = 'Decompressing bzip2...';
              break;
            case 'decompressed':
              final size = message['size'] as int?;
              if (size != null) {
                statusText =
                    'Decompressed ${(size / 1024 / 1024).toStringAsFixed(1)} MB';
              }
              break;
            case 'decoding':
              statusText = 'Decoding tar archive...';
              break;
            case 'decoded':
              statusText = 'Decoded ${message['fileCount']} files';
              break;
            case 'extracting':
              if (fileCount != null && totalFiles != null) {
                statusText = 'Extracting files... ($fileCount/$totalFiles)';
                if (currentFile != null) {
                  final fileName = currentFile.split('/').last;
                  statusText += '\n$fileName';
                }
              }
              break;
            case 'completed':
              statusText =
                  'Extraction complete! (${message['fileCount']} files)';
              break;
          }

          _extractionStatus = statusText;

          setState(() {
            _statusMessage =
                'Extracting model... (${progress.toStringAsFixed(1)}%)\n$_extractionStatus';
          });

          print(
            'Extraction progress: ${progress.toStringAsFixed(1)}% - $statusText',
          );

          if (status == 'completed') {
            break;
          }
        }
      }

      // Verify extracted files exist and find/rename them if needed
      await _verifyAndCopyModelFiles();

      if (mounted) {
        setState(() {
          _extractionProgress = 100.0;
          _statusMessage = 'Model extracted successfully';
        });
      }
    } catch (e, stackTrace) {
      print('Error extracting model: $e');
      print('Stack trace: $stackTrace');
      throw Exception('Error extracting model: $e');
    }
  }

  /// Find model files in the model directory (recursively)
  Future<Map<String, File?>> _findModelFiles() async {
    final foundFiles = <String, File?>{
      'encoder': null,
      'decoder': null,
      'joiner': null,
      'tokens': null,
    };

    final modelDir = Directory(_modelDir!);
    if (!await modelDir.exists()) {
      return foundFiles;
    }

    await for (final entity in modelDir.list(recursive: true)) {
      if (entity is File) {
        final name = entity.path.split('/').last.toLowerCase();
        final path = entity.path;

        // Find encoder (look for files starting with "encoder" and ending with ".onnx")
        // Prefer non-INT8 versions
        if (name.startsWith('encoder') && name.endsWith('.onnx')) {
          if (foundFiles['encoder'] == null) {
            foundFiles['encoder'] = entity;
            print('Found encoder: $path');
          } else if (!name.contains('.int8') &&
              foundFiles['encoder']!.path.toLowerCase().contains('.int8')) {
            // Prefer non-INT8 version
            foundFiles['encoder'] = entity;
            print('Found better encoder (non-INT8): $path');
          }
        }
        // Find decoder (look for files starting with "decoder" and ending with ".onnx")
        // Prefer non-INT8 versions
        if (name.startsWith('decoder') && name.endsWith('.onnx')) {
          if (foundFiles['decoder'] == null) {
            foundFiles['decoder'] = entity;
            print('Found decoder: $path');
          } else if (!name.contains('.int8') &&
              foundFiles['decoder']!.path.toLowerCase().contains('.int8')) {
            // Prefer non-INT8 version
            foundFiles['decoder'] = entity;
            print('Found better decoder (non-INT8): $path');
          }
        }
        // Find joiner (look for files starting with "joiner" and ending with ".onnx")
        // Prefer non-INT8 versions
        if (name.startsWith('joiner') && name.endsWith('.onnx')) {
          if (foundFiles['joiner'] == null) {
            foundFiles['joiner'] = entity;
            print('Found joiner: $path');
          } else if (!name.contains('.int8') &&
              foundFiles['joiner']!.path.toLowerCase().contains('.int8')) {
            // Prefer non-INT8 version
            foundFiles['joiner'] = entity;
            print('Found better joiner (non-INT8): $path');
          }
        }
        // Find tokens.txt
        if (foundFiles['tokens'] == null && name == 'tokens.txt') {
          foundFiles['tokens'] = entity;
          print('Found tokens: $path');
        }
      }
    }

    return foundFiles;
  }

  /// Verify model files exist and copy them to expected names if needed
  Future<void> _verifyAndCopyModelFiles() async {
    final encoderFile = File('$_modelDir/encoder.onnx');
    final decoderFile = File('$_modelDir/decoder.onnx');
    final joinerFile = File('$_modelDir/joiner.onnx');
    final tokensFile = File('$_modelDir/tokens.txt');

    // If files not in root with expected names, search and rename/copy
    if (!await encoderFile.exists() ||
        !await decoderFile.exists() ||
        !await joinerFile.exists() ||
        !await tokensFile.exists()) {
      print('Model files not found with expected names, searching...');
      final foundFiles = await _findModelFiles();

      // Copy/rename files to expected names in root
      if (foundFiles['encoder'] != null && !await encoderFile.exists()) {
        await foundFiles['encoder']!.copy(encoderFile.path);
        print('Copied encoder to: ${encoderFile.path}');
      }
      if (foundFiles['decoder'] != null && !await decoderFile.exists()) {
        await foundFiles['decoder']!.copy(decoderFile.path);
        print('Copied decoder to: ${decoderFile.path}');
      }
      if (foundFiles['joiner'] != null && !await joinerFile.exists()) {
        await foundFiles['joiner']!.copy(joinerFile.path);
        print('Copied joiner to: ${joinerFile.path}');
      }
      if (foundFiles['tokens'] != null && !await tokensFile.exists()) {
        await foundFiles['tokens']!.copy(tokensFile.path);
        print('Copied tokens to: ${tokensFile.path}');
      }
    }
  }

  Future<void> _startRecording() async {
    try {
      // Check permissions
      if (await _audioRecorder.hasPermission() == false) {
        setState(() {
          _statusMessage = 'Microphone permission denied';
        });
        return;
      }

      // Get temporary directory for recording
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      _currentRecordingPath = '${tempDir.path}/recording_$timestamp.wav';

      // Start recording
      await _audioRecorder.start(
        const RecordConfig(
          encoder: AudioEncoder.wav,
          sampleRate: 16000,
          numChannels: 1,
        ),
        path: _currentRecordingPath!,
      );

      setState(() {
        _isRecording = true;
        _transcription = 'Recording...';
        _statusMessage = 'Recording audio...';
        _recordingDuration = Duration.zero;
      });

      // Start timer to show recording duration
      _recordingTimer = Timer.periodic(const Duration(seconds: 1), (timer) {
        setState(() {
          _recordingDuration = Duration(seconds: timer.tick);
        });
      });
    } catch (e) {
      setState(() {
        _isRecording = false;
        _statusMessage = 'Error starting recording: $e';
      });
      print('Error starting recording: $e');
    }
  }

  Future<void> _stopRecording() async {
    try {
      _recordingTimer?.cancel();
      _recordingTimer = null;

      final path = await _audioRecorder.stop();
      if (path != null) {
        _currentRecordingPath = path;
      }

      setState(() {
        _isRecording = false;
        _statusMessage = 'Recording stopped. Transcribing...';
      });

      // Automatically transcribe after stopping
      await _transcribeAudio();
    } catch (e) {
      setState(() {
        _isRecording = false;
        _statusMessage = 'Error stopping recording: $e';
      });
      print('Error stopping recording: $e');
    }
  }

  Future<void> _transcribeAudio() async {
    if (_recognizer == null ||
        _currentRecordingPath == null ||
        _modelDir == null) {
      setState(() {
        _statusMessage =
            'Sherpa-ONNX not initialized or no recording available';
      });
      return;
    }

    final audioFile = File(_currentRecordingPath!);
    if (!await audioFile.exists()) {
      setState(() {
        _statusMessage = 'Recording file not found';
      });
      return;
    }

    setState(() {
      _isTranscribing = true;
      _transcriptionElapsedTime = Duration.zero;
      _statusMessage =
          'Transcribing audio... (Elapsed: ${_formatDuration(_transcriptionElapsedTime)})';
      _transcription = 'Processing...';
      _showOutput = false;
    });

    // Start elapsed time timer
    _transcriptionTimer = Timer.periodic(const Duration(seconds: 1), (timer) {
      if (mounted) {
        setState(() {
          _transcriptionElapsedTime = Duration(seconds: timer.tick);
          _statusMessage =
              'Transcribing audio... (Elapsed: ${_formatDuration(_transcriptionElapsedTime)})';
        });
      }
    });

    try {
      // Create offline stream for transcription
      final stream = _recognizer!.createStream();

      // Read audio file and feed to recognizer
      final audioBytes = await audioFile.readAsBytes();

      // Process audio in chunks (16kHz, 16-bit, mono = 32000 bytes per second)
      const chunkSize = 3200; // 100ms chunks
      for (int i = 0; i < audioBytes.length; i += chunkSize) {
        final end = (i + chunkSize < audioBytes.length)
            ? i + chunkSize
            : audioBytes.length;
        final chunk = audioBytes.sublist(i, end);
        stream.acceptWaveform(
          samples: _bytesToSamples(chunk),
          sampleRate: 16000,
        );

        if (_showOutput && mounted) {
          // Get partial result if showing output
          try {
            _recognizer!.decode(stream);
            final partialResult = _recognizer!.getResult(stream);
            if (partialResult.text.isNotEmpty && mounted) {
              setState(() {
                _transcription = partialResult.text;
              });
            }
          } catch (e) {
            // Ignore errors for partial results
          }
        }
      }

      // Input finished, decode and get final result
      String finalText = 'No transcription available';
      try {
        _recognizer!.decode(stream);
        final result = _recognizer!.getResult(stream);
        finalText = result.text.isNotEmpty ? result.text : 'No speech detected';
        print('Transcription result: $finalText');
      } catch (e) {
        print('Error getting final result: $e');
        finalText = 'Error retrieving transcription result: $e';
      } finally {
        // Clean up stream
        stream.free();
      }

      _transcriptionTimer?.cancel();
      _transcriptionTimer = null;

      setState(() {
        _isTranscribing = false;
        _transcription = finalText;
        _statusMessage = 'Transcription complete';
      });
    } catch (e) {
      _transcriptionTimer?.cancel();
      _transcriptionTimer = null;
      setState(() {
        _isTranscribing = false;
        _statusMessage = 'Error transcribing: $e';
        _transcription = 'Error: $e';
      });
      print('Error transcribing: $e');
    }
  }

  // Convert bytes to float samples (16-bit PCM to float32)
  Float32List _bytesToSamples(List<int> bytes) {
    final sampleCount = bytes.length ~/ 2;
    final samples = Float32List(sampleCount);
    for (int i = 0; i < bytes.length - 1; i += 2) {
      // Combine two bytes into a 16-bit signed integer
      final sample = (bytes[i] | (bytes[i + 1] << 8));
      // Convert to signed 16-bit
      final signedSample = sample > 32767 ? sample - 65536 : sample;
      // Normalize to [-1.0, 1.0]
      samples[i ~/ 2] = signedSample / 32768.0;
    }
    return samples;
  }

  Future<void> _changeModel(SherpaModelType model) async {
    if (model == selectedModel) return;

    // Dispose current recognizer
    _recognizer = null;

    setState(() {
      selectedModel = model;
      _transcription = 'Press the button to start recording';
    });

    // Re-initialize with new model (uses the same logic as _initializeSherpa)
    await _initializeSherpa();
  }

  Future<void> _changeLanguage(Language lang) async {
    setState(() {
      selectedLang = lang;
    });
  }

  String _formatDuration(Duration duration) {
    String twoDigits(int n) => n.toString().padLeft(2, '0');
    final minutes = twoDigits(duration.inMinutes.remainder(60));
    final seconds = twoDigits(duration.inSeconds.remainder(60));
    return '$minutes:$seconds';
  }

  @override
  void dispose() {
    _recordingTimer?.cancel();
    _transcriptionTimer?.cancel();
    _streamSubscription?.cancel();
    _audioRecorder.dispose();
    // Note: OfflineRecognizer may not have dispose, cleanup is handled automatically
    _recognizer = null;
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text('Sherpa-ONNX STT - Multilingual'),
        actions: [
          // Model selector
          PopupMenuButton<SherpaModelType>(
            onSelected: _changeModel,
            itemBuilder: (BuildContext context) => SherpaModelType.values
                .map(
                  (m) => CheckedPopupMenuItem<SherpaModelType>(
                    value: m,
                    checked: selectedModel == m,
                    child: Column(
                      crossAxisAlignment: CrossAxisAlignment.start,
                      mainAxisSize: MainAxisSize.min,
                      children: [
                        Text(m.displayName),
                        Text(
                          m.fileSize,
                          style: TextStyle(
                            fontSize: 12,
                            color: Colors.grey[600],
                          ),
                        ),
                      ],
                    ),
                  ),
                )
                .toList(),
          ),
          // Language selector
          PopupMenuButton<Language>(
            onSelected: _changeLanguage,
            itemBuilder: (BuildContext context) => languages
                .map(
                  (l) => CheckedPopupMenuItem<Language>(
                    value: l,
                    checked: selectedLang == l,
                    child: Text(l.name),
                  ),
                )
                .toList(),
          ),
        ],
      ),
      body: SafeArea(
        child: Padding(
          padding: const EdgeInsets.all(16.0),
          child: SingleChildScrollView(
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.stretch,
              children: [
                const SizedBox(height: 20),
                // Status message
                Container(
                  padding: const EdgeInsets.all(12.0),
                  decoration: BoxDecoration(
                    color: _isInitializing || _isTranscribing || _isDownloading
                        ? Colors.orange[50]
                        : _statusMessage.contains('Error')
                        ? Colors.red[50]
                        : Colors.green[50],
                    borderRadius: BorderRadius.circular(8),
                    border: Border.all(
                      color:
                          _isInitializing || _isTranscribing || _isDownloading
                          ? Colors.orange[200]!
                          : _statusMessage.contains('Error')
                          ? Colors.red[200]!
                          : Colors.green[200]!,
                    ),
                  ),
                  child: Row(
                    children: [
                      if (_isInitializing || _isTranscribing || _isDownloading)
                        const Padding(
                          padding: EdgeInsets.only(right: 8.0),
                          child: SizedBox(
                            width: 16,
                            height: 16,
                            child: CircularProgressIndicator(strokeWidth: 2),
                          ),
                        ),
                      Expanded(
                        child: Text(
                          _statusMessage,
                          style: const TextStyle(fontSize: 14),
                        ),
                      ),
                    ],
                  ),
                ),
                const SizedBox(height: 16),
                // Extraction progress bar
                if (_isDownloading && _extractionProgress > 0)
                  Container(
                    padding: const EdgeInsets.all(12.0),
                    decoration: BoxDecoration(
                      color: Colors.blue[50],
                      borderRadius: BorderRadius.circular(8),
                      border: Border.all(color: Colors.blue[200]!),
                    ),
                    child: Column(
                      crossAxisAlignment: CrossAxisAlignment.start,
                      children: [
                        Row(
                          mainAxisAlignment: MainAxisAlignment.spaceBetween,
                          children: [
                            Text(
                              'Extraction Progress',
                              style: TextStyle(
                                fontSize: 14,
                                fontWeight: FontWeight.bold,
                                color: Colors.blue[700],
                              ),
                            ),
                            Text(
                              '${_extractionProgress.toStringAsFixed(1)}%',
                              style: TextStyle(
                                fontSize: 14,
                                fontWeight: FontWeight.bold,
                                color: Colors.blue[700],
                              ),
                            ),
                          ],
                        ),
                        const SizedBox(height: 8),
                        LinearProgressIndicator(
                          value: _extractionProgress / 100.0,
                          backgroundColor: Colors.blue[100],
                          valueColor: AlwaysStoppedAnimation<Color>(
                            Colors.blue,
                          ),
                        ),
                        if (_extractionStatus.isNotEmpty) ...[
                          const SizedBox(height: 8),
                          Text(
                            _extractionStatus,
                            style: TextStyle(
                              fontSize: 12,
                              color: Colors.blue[600],
                            ),
                          ),
                        ],
                      ],
                    ),
                  ),
                // Transcription elapsed time
                if (_isTranscribing)
                  Container(
                    padding: const EdgeInsets.all(12.0),
                    decoration: BoxDecoration(
                      color: Colors.orange[50],
                      borderRadius: BorderRadius.circular(8),
                      border: Border.all(color: Colors.orange[200]!),
                    ),
                    child: Row(
                      mainAxisAlignment: MainAxisAlignment.center,
                      children: [
                        Icon(
                          Icons.hourglass_empty,
                          color: Colors.orange[700],
                          size: 20,
                        ),
                        const SizedBox(width: 8),
                        Text(
                          'Processing: ${_formatDuration(_transcriptionElapsedTime)}',
                          style: TextStyle(
                            fontSize: 16,
                            fontWeight: FontWeight.bold,
                            color: Colors.orange[700],
                          ),
                        ),
                      ],
                    ),
                  ),
                // Recording duration
                if (_isRecording)
                  Container(
                    padding: const EdgeInsets.all(12.0),
                    decoration: BoxDecoration(
                      color: Colors.red[50],
                      borderRadius: BorderRadius.circular(8),
                      border: Border.all(color: Colors.red[200]!),
                    ),
                    child: Row(
                      mainAxisAlignment: MainAxisAlignment.center,
                      children: [
                        Icon(Icons.mic, color: Colors.red[700], size: 20),
                        const SizedBox(width: 8),
                        Text(
                          _formatDuration(_recordingDuration),
                          style: TextStyle(
                            fontSize: 18,
                            fontWeight: FontWeight.bold,
                            color: Colors.red[700],
                          ),
                        ),
                      ],
                    ),
                  ),
                const SizedBox(height: 16),
                // Transcription result
                Container(
                  padding: const EdgeInsets.all(16.0),
                  decoration: BoxDecoration(
                    color: Colors.blue[50],
                    borderRadius: BorderRadius.circular(8),
                    border: Border.all(color: Colors.blue[200]!),
                  ),
                  child: Column(
                    crossAxisAlignment: CrossAxisAlignment.start,
                    children: [
                      const Text(
                        'Transcription:',
                        style: TextStyle(
                          fontSize: 16,
                          fontWeight: FontWeight.bold,
                          color: Colors.grey,
                        ),
                      ),
                      const SizedBox(height: 8),
                      SizedBox(
                        height: 200,
                        child: SingleChildScrollView(
                          child: Text(
                            _isTranscribing && !_showOutput
                                ? 'Processing... (Click "See Output" below to view real-time progress)'
                                : _transcription,
                            style: const TextStyle(fontSize: 18),
                          ),
                        ),
                      ),
                    ],
                  ),
                ),
                const SizedBox(height: 32),
                // Model and language info
                Text(
                  'Model: ${selectedModel.displayName} (${selectedModel.fileSize}) | Language: ${selectedLang.name} (${selectedLang.code})',
                  style: const TextStyle(fontSize: 14),
                  textAlign: TextAlign.center,
                ),
                const SizedBox(height: 20),
                // Record button
                ElevatedButton.icon(
                  onPressed:
                      (_isInitializing || _isTranscribing || _isDownloading)
                      ? null
                      : (_isRecording ? _stopRecording : _startRecording),
                  icon: Icon(_isRecording ? Icons.stop : Icons.mic, size: 24),
                  label: Text(
                    _isRecording ? 'Stop Recording' : 'Start Recording',
                    style: const TextStyle(fontSize: 18),
                  ),
                  style: ElevatedButton.styleFrom(
                    padding: const EdgeInsets.symmetric(
                      horizontal: 32,
                      vertical: 16,
                    ),
                    backgroundColor: _isRecording ? Colors.red : Colors.green,
                    foregroundColor: Colors.white,
                  ),
                ),
                // See Output button
                if (_isTranscribing)
                  Padding(
                    padding: const EdgeInsets.only(top: 12.0),
                    child: ElevatedButton.icon(
                      onPressed: () {
                        setState(() {
                          _showOutput = !_showOutput;
                        });
                      },
                      icon: Icon(
                        _showOutput ? Icons.visibility_off : Icons.visibility,
                        size: 20,
                      ),
                      label: Text(_showOutput ? 'Hide Output' : 'See Output'),
                      style: ElevatedButton.styleFrom(
                        backgroundColor: _showOutput
                            ? Colors.grey
                            : Colors.blue,
                        foregroundColor: Colors.white,
                      ),
                    ),
                  ),
                // Transcribe button (if we have a recording but haven't transcribed)
                if (!_isRecording &&
                    _currentRecordingPath != null &&
                    !_isTranscribing &&
                    _transcription == 'Press the button to start recording')
                  Padding(
                    padding: const EdgeInsets.only(top: 12.0),
                    child: ElevatedButton.icon(
                      onPressed: _transcribeAudio,
                      icon: const Icon(Icons.transcribe, size: 20),
                      label: const Text('Transcribe Last Recording'),
                      style: ElevatedButton.styleFrom(
                        backgroundColor: Colors.blue,
                        foregroundColor: Colors.white,
                      ),
                    ),
                  ),
              ],
            ),
          ),
        ),
      ),
    );
  }
}
